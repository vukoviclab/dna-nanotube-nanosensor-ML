{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47LN1izBJ-p",
        "outputId": "b810b702-e3e6-475c-96bb-24b903003c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.3.6\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.3.6)\n",
            "Collecting avalon_framework\n",
            "  Downloading avalon_framework-1.8.2.tar.gz (3.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Building wheels for collected packages: avalon_framework\n",
            "  Building wheel for avalon_framework (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avalon_framework: filename=avalon_framework-1.8.2-py3-none-any.whl size=3868 sha256=f719dc885edae734700992d37ecfef5d9b0ed3e821cbbdc5b72773507207bd08\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/77/90/553bfd64ca45f153cdc7c00667951a7f770c334c6aa5f74bad\n",
            "Successfully built avalon_framework\n",
            "Installing collected packages: avalon_framework\n",
            "Successfully installed avalon_framework-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install openpyxl\n",
        "!pip install rdkit avalon_framework"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SVC-only, 6 fingerprints, 200 random models each\n",
        "# - Trains 200 SVCs per FP\n",
        "# - Picks Top-5 by F1 in [0.75, 0.90]\n",
        "# - Saves mean ± stdev F1 of those exact Top-5 per FP\n",
        "# - Runs blind test with those Top-5 and writes one combined CSV\n",
        "# ============================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, MACCSkeys, rdMolDescriptors\n",
        "from rdkit.Avalon.pyAvalonTools import GetAvalonFP\n",
        "from rdkit.Chem.Fingerprints import FingerprintMols\n",
        "\n",
        "# Fixed-size Daylight-like generator (prevents variable bit lengths)\n",
        "try:\n",
        "    from rdkit.Chem.rdFingerprintGenerator import GetRDKitFPGenerator\n",
        "    _HAS_RDGEN = True\n",
        "except Exception:\n",
        "    _HAS_RDGEN = False\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix\n",
        "\n",
        "# -------------------------\n",
        "# File/column config\n",
        "# -------------------------\n",
        "TRAIN_FILE = \"INPUT-CORRECT-ML-CLASS.xlsx\"   # columns: Smiles, Class\n",
        "BLIND_FILE = \"INPUT-NEW-MOLS-correct.csv\"    # columns: Smiles, Cmpd Label\n",
        "SMILES_COL_TRAIN = \"Smiles\"\n",
        "CLASS_COL = \"Class\"\n",
        "SMILES_COL_BLIND = \"Smiles\"\n",
        "NAME_COL_BLIND = \"Cmpd Label\"\n",
        "\n",
        "# -------------------------\n",
        "# Fingerprint builders\n",
        "# -------------------------\n",
        "def build_morgan(m):\n",
        "    return AllChem.GetMorganFingerprintAsBitVect(m, radius=2, nBits=2048)\n",
        "\n",
        "def build_maccs(m):\n",
        "    return MACCSkeys.GenMACCSKeys(m)  # 167 bits\n",
        "\n",
        "def build_daylight(m):\n",
        "    if _HAS_RDGEN:\n",
        "        # Fixed-size \"RDKit (Daylight-like)\" 2048-bit\n",
        "        gen = GetRDKitFPGenerator(fpSize=2048, minPath=1, maxPath=7)\n",
        "        return gen.GetFingerprint(m)\n",
        "    # Fallback: fixed size with FingerprintMols\n",
        "    return FingerprintMols.FingerprintMol(m, fpSize=2048, minPath=1, maxPath=7, tgtDensity=0.0, minSize=2048)\n",
        "\n",
        "def build_atompairs(m):\n",
        "    return rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(m, nBits=2048)\n",
        "\n",
        "def build_torsion(m):\n",
        "    return rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(m, nBits=2048)\n",
        "\n",
        "def build_avalon(m):\n",
        "    return GetAvalonFP(m, nBits=1024)\n",
        "\n",
        "FP_BUILDERS = {\n",
        "    \"Morgan\": build_morgan,\n",
        "    \"MACCS\": build_maccs,\n",
        "    \"Daylight\": build_daylight,\n",
        "    \"AtomPairs\": build_atompairs,\n",
        "    \"Torsion\": build_torsion,\n",
        "    \"Avalon\": build_avalon\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Data load\n",
        "# -------------------------\n",
        "train_df = pd.read_excel(TRAIN_FILE)\n",
        "blind_df = pd.read_csv(BLIND_FILE)\n",
        "\n",
        "train_smiles = train_df[SMILES_COL_TRAIN].tolist()\n",
        "y_all = train_df[CLASS_COL].astype(int).values\n",
        "\n",
        "blind_smiles = blind_df[SMILES_COL_BLIND].tolist()\n",
        "blind_names = blind_df[NAME_COL_BLIND].tolist()\n",
        "\n",
        "mols_train = [Chem.MolFromSmiles(s) for s in train_smiles]\n",
        "mols_blind = [Chem.MolFromSmiles(s) for s in blind_smiles]\n",
        "\n",
        "# filter invalid SMILES\n",
        "def _valid(m): return m is not None\n",
        "tr_idx = [i for i,m in enumerate(mols_train) if _valid(m)]\n",
        "bl_idx = [i for i,m in enumerate(mols_blind) if _valid(m)]\n",
        "\n",
        "if len(tr_idx) != len(mols_train):\n",
        "    print(f\"Warning: dropped {len(mols_train)-len(tr_idx)} invalid training SMILES.\")\n",
        "if len(bl_idx) != len(mols_blind):\n",
        "    print(f\"Warning: dropped {len(mols_blind)-len(bl_idx)} invalid blind SMILES.\")\n",
        "\n",
        "mols_train = [mols_train[i] for i in tr_idx]\n",
        "y_all = y_all[tr_idx]\n",
        "mols_blind = [mols_blind[i] for i in bl_idx]\n",
        "blind_df = blind_df.iloc[bl_idx].reset_index(drop=True)  # keep rows aligned\n",
        "\n",
        "# -------------------------\n",
        "# Helper: make feature matrix like your code (list of lists of \"0\"/\"1\")\n",
        "# -------------------------\n",
        "def fps_to_bitstrings(fps):\n",
        "    # returns list of lists of \"0\"/\"1\" chars (your working pattern)\n",
        "    return [list(fp.ToBitString()) for fp in fps]\n",
        "\n",
        "# -------------------------\n",
        "# Master results containers\n",
        "# -------------------------\n",
        "summary_rows = []  # per-FP mean ± std F1 of Top-5\n",
        "# one combined blind predictions table collecting Top-5 preds per FP\n",
        "combined_pred_cols = {\n",
        "    \"Molecule Names\": blind_df[NAME_COL_BLIND].tolist(),\n",
        "    \"Molecule SMILES\": blind_df[SMILES_COL_BLIND].tolist()\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Settings like your code\n",
        "# -------------------------\n",
        "seed_value = 45\n",
        "np.random.seed(seed_value)\n",
        "num_models = 200\n",
        "f1_range_lower = 0.75\n",
        "f1_range_upper = 0.90\n",
        "\n",
        "# =========================\n",
        "# Loop over fingerprints\n",
        "# =========================\n",
        "for fp_name, builder in FP_BUILDERS.items():\n",
        "    print(f\"\\n=== Fingerprint: {fp_name} ===\")\n",
        "\n",
        "    # Build fingerprints for training & blind\n",
        "    train_fps = [builder(m) for m in mols_train]\n",
        "    blind_fps = [builder(m) for m in mols_blind]\n",
        "\n",
        "    # Convert like your code (strings \"0\"/\"1\")\n",
        "    fingerprints_list = fps_to_bitstrings(train_fps)\n",
        "\n",
        "    # Your style dataframe (not used later, but keep for parity)\n",
        "    new_df = pd.DataFrame({\"Class\": y_all, \"Fingerprints\": fingerprints_list})\n",
        "    features = np.array(fingerprints_list)\n",
        "\n",
        "    # Track metrics and Top-5 selection\n",
        "    metrics_list = []\n",
        "    confusion_matrix_list = []\n",
        "\n",
        "    top_models_indices = []\n",
        "    top_models_f1_scores = []\n",
        "    top_models_accuracies = []\n",
        "    top_models = []\n",
        "\n",
        "    # 200 models\n",
        "    for i in range(num_models):\n",
        "        perm = np.random.permutation(len(features))\n",
        "        shuffled_features = features[perm]\n",
        "        shuffled_labels = new_df[\"Class\"].values[perm]\n",
        "\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            shuffled_features, shuffled_labels, test_size=0.20, random_state=i\n",
        "        )\n",
        "\n",
        "        model = SVC(probability=True)  # same as your code\n",
        "        model.fit(x_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(x_test)  # same behavior as your code\n",
        "        y_prob = model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        rec = recall_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        metrics_list.append({\"Model\": i + 1, \"Accuracy\": acc, \"F1 Score\": f1, \"Recall\": rec})\n",
        "        confusion_matrix_list.append(cm)\n",
        "\n",
        "        if f1_range_lower <= f1 <= f1_range_upper:\n",
        "            top_models_indices.append(i)\n",
        "            top_models_f1_scores.append(f1)\n",
        "            top_models_accuracies.append(acc)\n",
        "            top_models.append(model)\n",
        "\n",
        "    # --- Sort Top models by F1 desc (and reorder the parallel lists) ---\n",
        "    if len(top_models_f1_scores) > 0:\n",
        "        order = np.argsort(top_models_f1_scores)[::-1]  # descending by F1\n",
        "        top_models = [top_models[j] for j in order]\n",
        "        top_models_indices = [top_models_indices[j] for j in order]\n",
        "        top_models_f1_scores = [top_models_f1_scores[j] for j in order]\n",
        "        top_models_accuracies = [top_models_accuracies[j] for j in order]\n",
        "\n",
        "    # Pick Top-5 (may be <5 if not enough in range)\n",
        "    k = min(5, len(top_models))\n",
        "    top5_models = top_models[:k]\n",
        "    top5_indices = top_models_indices[:k]\n",
        "    top5_f1 = top_models_f1_scores[:k]\n",
        "    top5_acc = top_models_accuracies[:k]\n",
        "\n",
        "    # Save per-FP top models info\n",
        "    info_fname = f\"class-topmodels_info-seed45-f1range-{fp_name}.csv\"\n",
        "    top_models_info = pd.DataFrame({\n",
        "        \"Model Index\": top5_indices,\n",
        "        \"F1 Score\": top5_f1,\n",
        "        \"Accuracy\": top5_acc\n",
        "    })\n",
        "    # Mean ± std of F1 for EXACT Top-5 (your ask)\n",
        "    if k > 0:\n",
        "        mean_f1 = float(np.mean(top5_f1))\n",
        "        std_f1 = float(np.std(top5_f1))\n",
        "        print(f\"[{fp_name}] Top-5 F1 mean ± std = {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "        top_models_info[\"Mean F1 (Top-5)\"] = mean_f1\n",
        "        top_models_info[\"Std F1 (Top-5)\"] = std_f1\n",
        "    else:\n",
        "        mean_f1 = float('nan')\n",
        "        std_f1 = float('nan')\n",
        "        print(f\"[{fp_name}] No models in F1 range {f1_range_lower}–{f1_range_upper}.\")\n",
        "    top_models_info.to_csv(info_fname, index=False)\n",
        "\n",
        "    # Add to per-FP summary table (6 rows total)\n",
        "    summary_rows.append({\n",
        "        \"fingerprint\": fp_name,\n",
        "        \"mean_f1_top5\": mean_f1,\n",
        "        \"std_f1_top5\": std_f1,\n",
        "        \"top5_f1_list\": \";\".join(f\"{v:.4f}\" for v in top5_f1)\n",
        "    })\n",
        "\n",
        "    # -------- Blind test with EXACT Top-5 (same as your code style) --------\n",
        "    # Prepare a per-FP predictions table (we'll also collect into a combined table)\n",
        "    fp_pred_cols = {}\n",
        "    fp_pred_cols[\"Molecule Names\"] = blind_df[NAME_COL_BLIND].tolist()\n",
        "    fp_pred_cols[\"Molecule SMILES\"] = blind_df[SMILES_COL_BLIND].tolist()\n",
        "\n",
        "    if k > 0:\n",
        "        # Use RDKit bitvectors directly like your code\n",
        "        new_fps = blind_fps\n",
        "\n",
        "        # Store each model's predictions and a simple ensemble (majority vote)\n",
        "        model_preds = []\n",
        "        for idx_m, model in enumerate(top5_models, start=1):\n",
        "            preds = model.predict(new_fps)\n",
        "            fp_pred_cols[f\"{fp_name}_Model_{idx_m}_Pred\"] = preds\n",
        "            model_preds.append(preds.astype(int))\n",
        "\n",
        "            # also add to combined table under unique column name\n",
        "            combined_pred_cols[f\"{fp_name}_Model_{idx_m}_Pred\"] = preds\n",
        "\n",
        "        # Majority vote across the Top-5 for this fingerprint\n",
        "        model_preds = np.vstack(model_preds)  # (k, N_blind)\n",
        "        vote_fraction = model_preds.mean(axis=0)  # fraction positive\n",
        "        fp_pred_cols[f\"{fp_name}_VoteFraction_Top{k}\"] = vote_fraction\n",
        "        combined_pred_cols[f\"{fp_name}_VoteFraction_Top{k}\"] = vote_fraction\n",
        "\n",
        "        # Save a per-FP predictions csv if you want (optional):\n",
        "        # pd.DataFrame(fp_pred_cols).to_csv(f\"class-predictions-seed45-{fp_name}.csv\", index=False)\n",
        "    else:\n",
        "        # no models: fill NaNs\n",
        "        combined_pred_cols[f\"{fp_name}_VoteFraction_Top0\"] = np.nan\n",
        "\n",
        "# -------------------------\n",
        "# Save per-FP Top-5 F1 summary (6 rows)\n",
        "# -------------------------\n",
        "summary_df = pd.DataFrame(summary_rows, columns=[\"fingerprint\", \"mean_f1_top5\", \"std_f1_top5\", \"top5_f1_list\"])\n",
        "summary_df.to_csv(\"top5_f1_summary_per_fingerprint.csv\", index=False)\n",
        "print(\"\\nSaved: top5_f1_summary_per_fingerprint.csv\")\n",
        "print(summary_df)\n",
        "\n",
        "# -------------------------\n",
        "# Save combined blind predictions table\n",
        "# -------------------------\n",
        "combined_pred_df = pd.DataFrame(combined_pred_cols)\n",
        "combined_pred_df.to_csv(\"blind_test_predictions_allfps.csv\", index=False)\n",
        "print(\"\\nSaved: blind_test_predictions_allfps.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjZ0FxnCGx_c",
        "outputId": "3f7f3d30-a65f-4cb5-c287-86c27b06be5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fingerprint: Morgan ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n",
            "[20:39:27] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Morgan] Top-5 F1 mean ± std = 0.9000 ± 0.0000\n",
            "\n",
            "=== Fingerprint: MACCS ===\n",
            "[MACCS] Top-5 F1 mean ± std = 0.8956 ± 0.0054\n",
            "\n",
            "=== Fingerprint: Daylight ===\n",
            "[Daylight] Top-5 F1 mean ± std = 0.8856 ± 0.0095\n",
            "\n",
            "=== Fingerprint: AtomPairs ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[20:40:05] DEPRECATION WARNING: please use AtomPairGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AtomPairs] Top-5 F1 mean ± std = 0.8911 ± 0.0044\n",
            "\n",
            "=== Fingerprint: Torsion ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[20:40:21] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Torsion] Top-5 F1 mean ± std = 0.8806 ± 0.0068\n",
            "\n",
            "=== Fingerprint: Avalon ===\n",
            "[Avalon] Top-5 F1 mean ± std = 0.8933 ± 0.0054\n",
            "\n",
            "Saved: top5_f1_summary_per_fingerprint.csv\n",
            "  fingerprint  mean_f1_top5  std_f1_top5                        top5_f1_list\n",
            "0      Morgan      0.900000     0.000000  0.9000;0.9000;0.9000;0.9000;0.9000\n",
            "1       MACCS      0.895556     0.005443  0.9000;0.9000;0.9000;0.8889;0.8889\n",
            "2    Daylight      0.885556     0.009526  0.9000;0.8889;0.8889;0.8750;0.8750\n",
            "3   AtomPairs      0.891111     0.004444  0.9000;0.8889;0.8889;0.8889;0.8889\n",
            "4     Torsion      0.880556     0.006804  0.8889;0.8889;0.8750;0.8750;0.8750\n",
            "5      Avalon      0.893333     0.005443  0.9000;0.9000;0.8889;0.8889;0.8889\n",
            "\n",
            "Saved: blind_test_predictions_allfps.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the combined predictions file (from previous step)\n",
        "pred_df = pd.read_csv(\"blind_test_predictions_allfps.csv\")\n",
        "\n",
        "# Identify model prediction columns (those that end with \"_Pred\")\n",
        "model_cols = [c for c in pred_df.columns if c.endswith(\"_Pred\")]\n",
        "\n",
        "print(f\"Found {len(model_cols)} model prediction columns.\")\n",
        "\n",
        "# Convert to numpy array (rows = molecules, cols = models)\n",
        "model_preds = pred_df[model_cols].values.astype(float)\n",
        "\n",
        "# Compute ensemble outputs\n",
        "# Fraction of models voting \"1\"\n",
        "ensemble_vote_fraction = model_preds.mean(axis=1)\n",
        "\n",
        "# Hard ensemble prediction (majority vote, >= 0.5 threshold)\n",
        "ensemble_majority = (ensemble_vote_fraction >= 0.5).astype(int)\n",
        "\n",
        "# Add to DataFrame\n",
        "pred_df[\"Ensemble30_VoteFraction\"] = ensemble_vote_fraction\n",
        "pred_df[\"Ensemble30_Pred\"] = ensemble_majority\n",
        "\n",
        "# Save to new file\n",
        "pred_df.to_csv(\"blind_test_predictions_with_ensemble.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved: blind_test_predictions_with_ensemble.csv\")\n",
        "print(\"Example ensemble output (first 5 rows):\")\n",
        "print(pred_df[[\"Molecule Names\", \"Ensemble30_VoteFraction\", \"Ensemble30_Pred\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6lF950LHaK4",
        "outputId": "a3048379-9b2d-453e-abcd-32388e34c847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 model prediction columns.\n",
            "\n",
            "Saved: blind_test_predictions_with_ensemble.csv\n",
            "Example ensemble output (first 5 rows):\n",
            "  Molecule Names  Ensemble30_VoteFraction  Ensemble30_Pred\n",
            "0            AAA                 1.000000                1\n",
            "1            BBB                 1.000000                1\n",
            "2            CCC                 0.933333                1\n",
            "3            DDD                 1.000000                1\n",
            "4            EEE                 0.233333                0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import to_rgba\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# --- 1) Load experimental dFF and binarize with threshold 0.3 ---\n",
        "expt_path = \"expt-dff.xlsx\"  # change if needed\n",
        "expt_df = pd.read_excel(expt_path, header=None)  # your file preview had no headers\n",
        "expt_df.columns = [\"Molecule\", \"dFF_exp\"]\n",
        "expt_df[\"Molecule\"] = expt_df[\"Molecule\"].astype(str).str.strip()\n",
        "expt_df[\"True\"] = (expt_df[\"dFF_exp\"] >= 0.3).astype(int)\n",
        "\n",
        "# --- 2) Load ensemble predictions (first = name, last = ensemble pred) ---\n",
        "ens_path = \"blind_test_predictions_with_ensemble.csv\"  # change if needed\n",
        "ens_df = pd.read_csv(ens_path)\n",
        "ens_df.iloc[:, 0] = ens_df.iloc[:, 0].astype(str).str.strip()\n",
        "\n",
        "name_col = ens_df.columns[0]\n",
        "pred_col = ens_df.columns[-1]   # expected to be a 0/1 class like 'Ensemble30_Pred'\n",
        "\n",
        "ens_small = ens_df[[name_col, pred_col]].copy()\n",
        "ens_small.columns = [\"Molecule\", \"Pred\"]\n",
        "ens_small[\"Pred\"] = ens_small[\"Pred\"].astype(int)\n",
        "\n",
        "# --- 3) Align by molecule name (inner join) ---\n",
        "merged = pd.merge(expt_df[[\"Molecule\", \"True\"]], ens_small, on=\"Molecule\", how=\"inner\")\n",
        "y_true = merged[\"True\"].values\n",
        "y_pred = merged[\"Pred\"].values\n",
        "\n",
        "# --- 4) Confusion matrix (order: [[TN, FP], [FN, TP]]) ---\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "\n",
        "# --- 5) Custom colors per cell ---\n",
        "# TN(0,0)=dark red, FP(0,1)=light blue, FN(1,0)=light red, TP(1,1)=dark blue\n",
        "# (you can tweak hex codes if you want slightly different shades)\n",
        "colors_hex = {\n",
        "    \"TN\": \"#8B0000\",  # dark red\n",
        "    \"FP\": \"#ADD8E6\",  # light blue\n",
        "    \"FN\": \"#FFA07A\",  # light red (light salmon)\n",
        "    \"TP\": \"#00008B\"   # dark blue\n",
        "}\n",
        "alpha = 1.0  # set <1.0 if you also want global transparency\n",
        "\n",
        "rgba_grid = np.zeros((2, 2, 4), dtype=float)\n",
        "rgba_grid[0, 0] = to_rgba(colors_hex[\"TN\"], alpha=alpha)  # TN\n",
        "rgba_grid[0, 1] = to_rgba(colors_hex[\"FP\"], alpha=alpha)  # FP\n",
        "rgba_grid[1, 0] = to_rgba(colors_hex[\"FN\"], alpha=alpha)  # FN\n",
        "rgba_grid[1, 1] = to_rgba(colors_hex[\"TP\"], alpha=alpha)  # TP\n",
        "\n",
        "# --- 6) Plot ---\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "# draw the colored blocks\n",
        "ax.imshow(rgba_grid, interpolation=\"nearest\")\n",
        "\n",
        "# overlay counts (black text, size 20)\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\", fontsize=20)\n",
        "\n",
        "# axes and labels\n",
        "ax.set_xticks([0, 1])\n",
        "ax.set_yticks([0, 1])\n",
        "ax.set_xticklabels([\"0\", \"1\"], fontsize=24)\n",
        "ax.set_yticklabels([\"0\", \"1\"], fontsize=24)\n",
        "ax.set_xlabel(\"Predicted Label\", fontsize=28)\n",
        "ax.set_ylabel(\"True Label\", fontsize=28)\n",
        "\n",
        "# nice gridlines between cells (optional)\n",
        "ax.set_xticks(np.arange(-0.5, 2, 1), minor=True)\n",
        "ax.set_yticks(np.arange(-0.5, 2, 1), minor=True)\n",
        "ax.grid(which=\"minor\", color=\"white\", linestyle=\"-\", linewidth=2)\n",
        "ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix_custom_colors.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: confusion_matrix_custom_colors.png\")\n",
        "print(\"Confusion matrix (rows: True 0/1, cols: Pred 0/1):\\n\", cm)\n",
        "\n",
        "# --- Export confusion matrix for Origin ---\n",
        "# cm is a 2x2 numpy array in order [[TN, FP], [FN, TP]]\n",
        "import pandas as pd\n",
        "\n",
        "counts_df = pd.DataFrame(cm,\n",
        "                         index=[\"True 0\", \"True 1\"],\n",
        "                         columns=[\"Pred 0\", \"Pred 1\"])\n",
        "counts_df.to_csv(\"confusion_matrix_counts.csv\")  # matrix-style for Origin worksheet/matrix\n",
        "\n",
        "# Long form (True, Pred, Count) for Origin heatmap/contour plots\n",
        "long_df = counts_df.reset_index().melt(id_vars=\"index\",\n",
        "                                       var_name=\"Pred\",\n",
        "                                       value_name=\"Count\").rename(columns={\"index\": \"True\"})\n",
        "long_df.to_csv(\"confusion_matrix_long_for_origin.csv\", index=False)\n",
        "\n",
        "print(\"Saved: confusion_matrix_counts.csv and confusion_matrix_long_for_origin.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "oalMOhQMIsyn",
        "outputId": "29492bb4-3bd9-46fa-db43-3551c2b5988d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: confusion_matrix_custom_colors.png\n",
            "Confusion matrix (rows: True 0/1, cols: Pred 0/1):\n",
            " [[ 4  2]\n",
            " [ 3 12]]\n",
            "Saved: confusion_matrix_counts.csv and confusion_matrix_long_for_origin.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# also kernels varied"
      ],
      "metadata": {
        "id": "j5gl6ZIh0-PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SVC: 6 fingerprints × 3 kernels, 200 runs per combo\n",
        "# Selection:\n",
        "#   - Compute mean±std F1 for EACH fingerprint-kernel combo across its 200 runs\n",
        "#   - Rank combos by mean F1 and pick Top-K combos\n",
        "#   - For each selected combo, choose the single best run (highest F1) for blind test\n",
        "# Blind test:\n",
        "#   - Use the 5 chosen models (one per selected combo); add ensemble columns\n",
        "# ============================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, MACCSkeys, rdMolDescriptors\n",
        "from rdkit.Avalon.pyAvalonTools import GetAvalonFP\n",
        "from rdkit.Chem.Fingerprints import FingerprintMols\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# ---- Fixed-size Daylight-like generator (prevents variable-length) ----\n",
        "try:\n",
        "    from rdkit.Chem.rdFingerprintGenerator import GetRDKitFPGenerator\n",
        "    _HAS_RDGEN = True\n",
        "except Exception:\n",
        "    _HAS_RDGEN = False\n",
        "\n",
        "# -------------------------\n",
        "# File/column config\n",
        "# -------------------------\n",
        "TRAIN_FILE = \"INPUT-CORRECT-ML-CLASS.xlsx\"   # columns: Smiles, Class\n",
        "BLIND_FILE = \"INPUT-NEW-MOLS-correct.csv\"    # columns: Smiles, Cmpd Label\n",
        "SMILES_COL_TRAIN = \"Smiles\"\n",
        "CLASS_COL = \"Class\"\n",
        "SMILES_COL_BLIND = \"Smiles\"\n",
        "NAME_COL_BLIND = \"Cmpd Label\"\n",
        "\n",
        "# -------------------------\n",
        "# Fingerprint builders\n",
        "# -------------------------\n",
        "def build_morgan(m):\n",
        "    return AllChem.GetMorganFingerprintAsBitVect(m, radius=2, nBits=2048)\n",
        "\n",
        "def build_maccs(m):\n",
        "    return MACCSkeys.GenMACCSKeys(m)  # 167 bits\n",
        "\n",
        "def build_daylight(m):\n",
        "    if _HAS_RDGEN:\n",
        "        gen = GetRDKitFPGenerator(fpSize=2048, minPath=1, maxPath=7)\n",
        "        return gen.GetFingerprint(m)\n",
        "    return FingerprintMols.FingerprintMol(m, fpSize=2048, minPath=1, maxPath=7, tgtDensity=0.0, minSize=2048)\n",
        "\n",
        "def build_atompairs(m):\n",
        "    return rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(m, nBits=2048)\n",
        "\n",
        "def build_torsion(m):\n",
        "    return rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(m, nBits=2048)\n",
        "\n",
        "def build_avalon(m):\n",
        "    return GetAvalonFP(m, nBits=1024)\n",
        "\n",
        "FP_BUILDERS = {\n",
        "    \"Morgan\": build_morgan,\n",
        "    \"MACCS\": build_maccs,\n",
        "    \"Daylight\": build_daylight,\n",
        "    \"AtomPairs\": build_atompairs,\n",
        "    \"Torsion\": build_torsion,\n",
        "    \"Avalon\": build_avalon\n",
        "}\n",
        "\n",
        "KERNELS = [\"rbf\", \"linear\", \"sigmoid\"]\n",
        "SELECT_TOP_K_COMBOS = 5  # <- change if you want more/less than 5\n",
        "\n",
        "# -------------------------\n",
        "# Data load\n",
        "# -------------------------\n",
        "train_df = pd.read_excel(TRAIN_FILE)\n",
        "blind_df = pd.read_csv(BLIND_FILE)\n",
        "\n",
        "train_smiles = train_df[SMILES_COL_TRAIN].tolist()\n",
        "y_all = train_df[CLASS_COL].astype(int).values\n",
        "\n",
        "blind_smiles = blind_df[SMILES_COL_BLIND].tolist()\n",
        "\n",
        "mols_train = [Chem.MolFromSmiles(s) for s in train_smiles]\n",
        "mols_blind = [Chem.MolFromSmiles(s) for s in blind_smiles]\n",
        "\n",
        "# filter invalid SMILES\n",
        "def _valid(m): return m is not None\n",
        "tr_idx = [i for i,m in enumerate(mols_train) if _valid(m)]\n",
        "bl_idx = [i for i,m in enumerate(mols_blind) if _valid(m)]\n",
        "\n",
        "if len(tr_idx) != len(mols_train):\n",
        "    print(f\"Warning: dropped {len(mols_train)-len(tr_idx)} invalid training SMILES.\")\n",
        "if len(bl_idx) != len(mols_blind):\n",
        "    print(f\"Warning: dropped {len(mols_blind)-len(bl_idx)} invalid blind SMILES.\")\n",
        "\n",
        "mols_train = [mols_train[i] for i in tr_idx]\n",
        "y_all = y_all[tr_idx]\n",
        "mols_blind = [mols_blind[i] for i in bl_idx]\n",
        "blind_df = blind_df.iloc[bl_idx].reset_index(drop=True)\n",
        "\n",
        "# -------------------------\n",
        "# Helper: features like your working code (list of lists of \"0\"/\"1\")\n",
        "# -------------------------\n",
        "def fps_to_bitstrings(fps):\n",
        "    return [list(fp.ToBitString()) for fp in fps]\n",
        "\n",
        "# -------------------------\n",
        "# Settings\n",
        "# -------------------------\n",
        "seed_value = 45\n",
        "np.random.seed(seed_value)\n",
        "num_runs_per_combo = 200\n",
        "\n",
        "# =========================\n",
        "# Precompute fingerprints once per FP\n",
        "# =========================\n",
        "train_fps_dict = {}\n",
        "blind_fps_dict = {}\n",
        "features_dict = {}\n",
        "for fp_name, builder in FP_BUILDERS.items():\n",
        "    tr_fps = [builder(m) for m in mols_train]\n",
        "    bl_fps = [builder(m) for m in mols_blind]\n",
        "    train_fps_dict[fp_name] = tr_fps\n",
        "    blind_fps_dict[fp_name] = bl_fps\n",
        "    features_dict[fp_name] = np.array(fps_to_bitstrings(tr_fps))  # training representation\n",
        "\n",
        "# =========================\n",
        "# Train across FP × Kernel (collect 200 F1s per combo)\n",
        "# =========================\n",
        "combo_f1s = {}    # (fp,kernel) -> list of 200 F1s\n",
        "combo_runs = {}   # (fp,kernel) -> list of dicts for each run (stores model + metrics)\n",
        "\n",
        "for fp_name in FP_BUILDERS.keys():\n",
        "    X_all = features_dict[fp_name]\n",
        "    y = y_all\n",
        "\n",
        "    for kernel in KERNELS:\n",
        "        key = (fp_name, kernel)\n",
        "        f1_list = []\n",
        "        runs_list = []\n",
        "\n",
        "        print(f\"\\n=== Fingerprint: {fp_name} | Kernel: {kernel} ===\")\n",
        "\n",
        "        for i in range(num_runs_per_combo):\n",
        "            # Shuffle then split exactly like your previous code\n",
        "            perm = np.random.permutation(len(X_all))\n",
        "            X_shuf = X_all[perm]\n",
        "            y_shuf = y[perm]\n",
        "\n",
        "            x_train, x_test, y_train, y_test = train_test_split(\n",
        "                X_shuf, y_shuf, test_size=0.20, random_state=i\n",
        "            )\n",
        "\n",
        "            clf = SVC(kernel=kernel, probability=True)\n",
        "            clf.fit(x_train, y_train)\n",
        "\n",
        "            y_pred = clf.predict(x_test)  # same style as your code\n",
        "            f1 = float(f1_score(y_test, y_pred))\n",
        "            acc = float(accuracy_score(y_test, y_pred))\n",
        "\n",
        "            f1_list.append(f1)\n",
        "            runs_list.append({\n",
        "                \"model\": clf, \"fp\": fp_name, \"kernel\": kernel,\n",
        "                \"run_idx\": i, \"f1\": f1, \"acc\": acc\n",
        "            })\n",
        "\n",
        "        combo_f1s[key] = f1_list\n",
        "        combo_runs[key] = runs_list\n",
        "\n",
        "# =========================\n",
        "# Rank combos by mean F1 and pick Top-K combos\n",
        "# =========================\n",
        "rows = []\n",
        "for (fp_name, kernel), f1_list in combo_f1s.items():\n",
        "    rows.append({\n",
        "        \"Fingerprint\": fp_name,\n",
        "        \"Kernel\": kernel,\n",
        "        \"Mean_F1_over_200\": float(np.mean(f1_list)),\n",
        "        \"Std_F1_over_200\": float(np.std(f1_list))\n",
        "    })\n",
        "combo_summary = pd.DataFrame(rows).sort_values(\"Mean_F1_over_200\", ascending=False)\n",
        "combo_summary.to_csv(\"combo_f1_summary.csv\", index=False)\n",
        "print(\"\\nSaved: combo_f1_summary.csv\")\n",
        "print(combo_summary)\n",
        "\n",
        "# select Top-K combos by mean F1\n",
        "topK_combos = combo_summary.head(SELECT_TOP_K_COMBOS).reset_index(drop=True)\n",
        "\n",
        "# For each selected combo, choose the single best run (highest F1) for blind test\n",
        "selected_models = []\n",
        "for idx, row in topK_combos.iterrows():\n",
        "    key = (row[\"Fingerprint\"], row[\"Kernel\"])\n",
        "    runs = combo_runs[key]\n",
        "    # best run within this combo\n",
        "    best_run = max(runs, key=lambda d: d[\"f1\"])\n",
        "    selected_models.append({\n",
        "        \"Rank\": idx + 1,\n",
        "        \"Fingerprint\": row[\"Fingerprint\"],\n",
        "        \"Kernel\": row[\"Kernel\"],\n",
        "        \"Mean_F1_over_200\": row[\"Mean_F1_over_200\"],\n",
        "        \"Std_F1_over_200\": row[\"Std_F1_over_200\"],\n",
        "        \"Chosen_Run_Index\": best_run[\"run_idx\"],\n",
        "        \"Chosen_Run_F1\": best_run[\"f1\"],\n",
        "        \"Chosen_Run_Acc\": best_run[\"acc\"],\n",
        "        \"model\": best_run[\"model\"]\n",
        "    })\n",
        "\n",
        "selected_df = pd.DataFrame(selected_models).drop(columns=[\"model\"])\n",
        "selected_df.to_csv(\"selected_top5_combos.csv\", index=False)\n",
        "print(\"\\nSaved: selected_top5_combos.csv\")\n",
        "print(selected_df)\n",
        "\n",
        "# =========================\n",
        "# Blind test with EXACT Top-K chosen models\n",
        "# =========================\n",
        "pred_cols = {\n",
        "    \"Molecule Names\": blind_df[NAME_COL_BLIND].tolist(),\n",
        "    \"Molecule SMILES\": blind_df[SMILES_COL_BLIND].tolist()\n",
        "}\n",
        "\n",
        "model_preds = []\n",
        "for rec in selected_models:\n",
        "    fp_name = rec[\"Fingerprint\"]\n",
        "    kernel = rec[\"Kernel\"]\n",
        "    clf = rec[\"model\"]\n",
        "\n",
        "    # NOTE: training used bitstring features; to keep your prior style, we use RDKit bitvectors here,\n",
        "    # which matched how you ran earlier. If needed, switch to bitstrings:\n",
        "    # new_X = np.array(fps_to_bitstrings(blind_fps_dict[fp_name]))\n",
        "    new_X = blind_fps_dict[fp_name]\n",
        "\n",
        "    preds = clf.predict(new_X)\n",
        "    colname = f\"Rank{rec['Rank']}_{fp_name}_{kernel}_Pred\"\n",
        "    pred_cols[colname] = preds\n",
        "    model_preds.append(preds.astype(int))\n",
        "\n",
        "# Ensemble (vote fraction & majority) across the selected models\n",
        "model_preds = np.vstack(model_preds)                 # (K, N_blind)\n",
        "vote_fraction = model_preds.mean(axis=0)             # fraction positive\n",
        "majority = (vote_fraction >= 0.5).astype(int)\n",
        "\n",
        "pred_cols[\"Ensemble_VoteFraction\"] = vote_fraction\n",
        "pred_cols[\"Ensemble_Pred\"] = majority\n",
        "\n",
        "pred_df = pd.DataFrame(pred_cols)\n",
        "pred_df.to_csv(\"blind_test_predictions_top5_combos.csv\", index=False)\n",
        "print(\"\\nSaved: blind_test_predictions_top5_combos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I57x3wy85EKG",
        "outputId": "6e372e50-5b67-4106-877d-083360d61cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use AtomPairGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n",
            "[22:42:18] DEPRECATION WARNING: please use TopologicalTorsionGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fingerprint: Morgan | Kernel: rbf ===\n",
            "\n",
            "=== Fingerprint: Morgan | Kernel: linear ===\n",
            "\n",
            "=== Fingerprint: Morgan | Kernel: sigmoid ===\n",
            "\n",
            "=== Fingerprint: MACCS | Kernel: rbf ===\n",
            "\n",
            "=== Fingerprint: MACCS | Kernel: linear ===\n",
            "\n",
            "=== Fingerprint: MACCS | Kernel: sigmoid ===\n",
            "\n",
            "=== Fingerprint: Daylight | Kernel: rbf ===\n",
            "\n",
            "=== Fingerprint: Daylight | Kernel: linear ===\n",
            "\n",
            "=== Fingerprint: Daylight | Kernel: sigmoid ===\n",
            "\n",
            "=== Fingerprint: AtomPairs | Kernel: rbf ===\n",
            "\n",
            "=== Fingerprint: AtomPairs | Kernel: linear ===\n",
            "\n",
            "=== Fingerprint: AtomPairs | Kernel: sigmoid ===\n",
            "\n",
            "=== Fingerprint: Torsion | Kernel: rbf ===\n",
            "\n",
            "=== Fingerprint: Torsion | Kernel: linear ===\n",
            "\n",
            "=== Fingerprint: Torsion | Kernel: sigmoid ===\n",
            "\n",
            "=== Fingerprint: Avalon | Kernel: rbf ===\n",
            "\n",
            "=== Fingerprint: Avalon | Kernel: linear ===\n",
            "\n",
            "=== Fingerprint: Avalon | Kernel: sigmoid ===\n",
            "\n",
            "Saved: combo_f1_summary.csv\n",
            "   Fingerprint   Kernel  Mean_F1_over_200  Std_F1_over_200\n",
            "2       Morgan  sigmoid          0.837420         0.092244\n",
            "0       Morgan      rbf          0.831409         0.099785\n",
            "9    AtomPairs      rbf          0.826267         0.103335\n",
            "14     Torsion  sigmoid          0.824196         0.107199\n",
            "17      Avalon  sigmoid          0.823178         0.103609\n",
            "11   AtomPairs  sigmoid          0.819742         0.100066\n",
            "3        MACCS      rbf          0.812606         0.108509\n",
            "5        MACCS  sigmoid          0.792873         0.111966\n",
            "1       Morgan   linear          0.787592         0.123680\n",
            "13     Torsion   linear          0.783971         0.108690\n",
            "10   AtomPairs   linear          0.781239         0.102691\n",
            "12     Torsion      rbf          0.778208         0.108493\n",
            "8     Daylight  sigmoid          0.776274         0.111213\n",
            "4        MACCS   linear          0.767572         0.120424\n",
            "15      Avalon      rbf          0.763059         0.124785\n",
            "16      Avalon   linear          0.755387         0.115948\n",
            "6     Daylight      rbf          0.743542         0.120466\n",
            "7     Daylight   linear          0.723445         0.131744\n",
            "\n",
            "Saved: selected_top5_combos.csv\n",
            "   Rank Fingerprint   Kernel  Mean_F1_over_200  Std_F1_over_200  \\\n",
            "0     1      Morgan  sigmoid          0.837420         0.092244   \n",
            "1     2      Morgan      rbf          0.831409         0.099785   \n",
            "2     3   AtomPairs      rbf          0.826267         0.103335   \n",
            "3     4     Torsion  sigmoid          0.824196         0.107199   \n",
            "4     5      Avalon  sigmoid          0.823178         0.103609   \n",
            "\n",
            "   Chosen_Run_Index  Chosen_Run_F1  Chosen_Run_Acc  \n",
            "0                27            1.0             1.0  \n",
            "1                10            1.0             1.0  \n",
            "2                16            1.0             1.0  \n",
            "3                62            1.0             1.0  \n",
            "4                 7            1.0             1.0  \n",
            "\n",
            "Saved: blind_test_predictions_top5_combos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# ========= CONFIG =========\n",
        "EXP_PATH  = \"expt-dff.xlsx\"                    # (col0: molecule name, col1: dFF)\n",
        "PRED_PATH = \"blind_test_predictions_top5_combos.csv\"  # from your 6x3x200 Top-K combo code\n",
        "NAME_COL_PRED = \"Molecule Names\"               # name column in predictions CSV\n",
        "CUTOFF   = 0.30                                 # dFF >= 0.3 -> class 1\n",
        "VOTE_THR = 0.50                                 # if we need to threshold vote fraction\n",
        "\n",
        "# Output folder (next to predictions)\n",
        "out_dir = Path(PRED_PATH).parent / \"confmat_outputs\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ========= Load experimental truth (threshold @ 0.3) =========\n",
        "exp_raw = pd.read_excel(EXP_PATH, header=None)\n",
        "df_exp = exp_raw.rename(columns={0: \"Molecule\", 1: \"dFF_expt\"})\n",
        "df_exp[\"Molecule\"] = df_exp[\"Molecule\"].astype(str).str.strip()\n",
        "df_exp[\"y_true\"]   = (df_exp[\"dFF_expt\"].astype(float) >= CUTOFF).astype(int)\n",
        "\n",
        "# ========= Load predictions (use ensemble by default) =========\n",
        "pred = pd.read_csv(PRED_PATH)\n",
        "pred[NAME_COL_PRED] = pred[NAME_COL_PRED].astype(str).str.strip()\n",
        "\n",
        "# Choose prediction column intelligently:\n",
        "pred_col = None\n",
        "if \"Ensemble_Pred\" in pred.columns:\n",
        "    pred_col = \"Ensemble_Pred\"                              # preferred binary 0/1\n",
        "elif \"Ensemble30_Pred\" in pred.columns:\n",
        "    pred_col = \"Ensemble30_Pred\"                            # older naming\n",
        "elif \"Ensemble_mean\" in pred.columns:\n",
        "    # If you have a probability/mean column, threshold it:\n",
        "    pred_col = \"Ensemble_mean\"\n",
        "    pred[\"__TEMP_PRED__\"] = (pred[pred_col].astype(float) >= VOTE_THR).astype(int)\n",
        "    pred_col = \"__TEMP_PRED__\"\n",
        "elif \"Ensemble_VoteFraction\" in pred.columns:\n",
        "    pred_col = \"Ensemble_VoteFraction\"\n",
        "    pred[\"__TEMP_PRED__\"] = (pred[pred_col].astype(float) >= VOTE_THR).astype(int)\n",
        "    pred_col = \"__TEMP_PRED__\"\n",
        "else:\n",
        "    # fallback: last column (often the ensemble 0/1); if not binary, we’ll try to binarize\n",
        "    last_col = pred.columns[-1]\n",
        "    if set(pd.unique(pred[last_col].dropna())).issubset({0, 1}):\n",
        "        pred_col = last_col\n",
        "    else:\n",
        "        pred[\"__TEMP_PRED__\"] = (pred[last_col].astype(float) >= VOTE_THR).astype(int)\n",
        "        pred_col = \"__TEMP_PRED__\"\n",
        "\n",
        "# Keep only name + chosen prediction\n",
        "pred_small = pred[[NAME_COL_PRED, pred_col]].copy()\n",
        "pred_small.columns = [\"Molecule\", \"y_pred\"]\n",
        "pred_small[\"y_pred\"] = pred_small[\"y_pred\"].astype(int)\n",
        "\n",
        "# ========= Align by molecule name =========\n",
        "merged = pd.merge(df_exp[[\"Molecule\", \"y_true\"]], pred_small, on=\"Molecule\", how=\"inner\")\n",
        "\n",
        "# (Optional) quick diagnostics\n",
        "missing_in_pred = set(df_exp[\"Molecule\"]) - set(pred_small[\"Molecule\"])\n",
        "missing_in_exp  = set(pred_small[\"Molecule\"]) - set(df_exp[\"Molecule\"])\n",
        "print(f\"Merged rows: {len(merged)} | Missing in predictions: {len(missing_in_pred)} | Missing in experimental: {len(missing_in_exp)}\")\n",
        "\n",
        "# ========= Confusion matrix (rows=true 0/1, cols=pred 0/1) =========\n",
        "y_true = merged[\"y_true\"].values\n",
        "y_pred = merged[\"y_pred\"].values\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Show textual summary\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(pd.DataFrame(cm, index=[\"True 0\",\"True 1\"], columns=[\"Pred 0\",\"Pred 1\"]))\n",
        "print(f\"\\nTN={tn}, FP={fp}, FN={fn}, TP={tp}\\n\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Class 0\",\"Class 1\"], digits=3))\n",
        "\n",
        "# ========= Save for Origin =========\n",
        "# 1) Matrix style (2x2)\n",
        "counts_df = pd.DataFrame(cm, index=[\"True 0\",\"True 1\"], columns=[\"Pred 0\",\"Pred 1\"])\n",
        "counts_df.to_csv(out_dir / \"confusion_matrix_counts.csv\")\n",
        "\n",
        "# 2) Long form (True, Pred, Count) – ideal for Origin heatmap/contour\n",
        "long_df = counts_df.reset_index().melt(id_vars=\"index\", var_name=\"Pred\", value_name=\"Count\").rename(columns={\"index\": \"True\"})\n",
        "long_df.to_csv(out_dir / \"confusion_matrix_long_for_origin-fp-kernels.csv\", index=False)\n",
        "\n",
        "# 3) Pairs (so you can audit which molecules landed where)\n",
        "pairs_df = merged[[\"Molecule\", \"y_true\", \"y_pred\"]].copy()\n",
        "pairs_df.to_csv(out_dir / \"y_true_pred_pairs.csv\", index=False)\n",
        "\n",
        "# 4) Compact TN/FP/FN/TP summary\n",
        "pd.DataFrame([{\"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp}]).to_csv(out_dir / \"confusion_summary.csv\", index=False)\n",
        "\n",
        "print(f\"\\nSaved files in: {out_dir.resolve()}\")\n",
        "print(\" - confusion_matrix_counts.csv\")\n",
        "print(\" - confusion_matrix_long_for_origin.csv\")\n",
        "print(\" - y_true_pred_pairs.csv\")\n",
        "print(\" - confusion_summary.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsvu_EX-7YjK",
        "outputId": "47fce2d4-4416-4bef-a3f1-e5707f7d011f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged rows: 21 | Missing in predictions: 0 | Missing in experimental: 0\n",
            "\n",
            "Confusion Matrix:\n",
            "        Pred 0  Pred 1\n",
            "True 0       4       2\n",
            "True 1       3      12\n",
            "\n",
            "TN=4, FP=2, FN=3, TP=12\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0      0.571     0.667     0.615         6\n",
            "     Class 1      0.857     0.800     0.828        15\n",
            "\n",
            "    accuracy                          0.762        21\n",
            "   macro avg      0.714     0.733     0.721        21\n",
            "weighted avg      0.776     0.762     0.767        21\n",
            "\n",
            "\n",
            "Saved files in: /content/confmat_outputs\n",
            " - confusion_matrix_counts.csv\n",
            " - confusion_matrix_long_for_origin.csv\n",
            " - y_true_pred_pairs.csv\n",
            " - confusion_summary.csv\n"
          ]
        }
      ]
    }
  ]
}